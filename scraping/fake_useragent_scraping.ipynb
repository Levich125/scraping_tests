{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping info on stock splits using fake_useragent and ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"origin\": \"46.216.27.102, 46.216.27.102\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = requests.session()\n",
    "session.proxies = {}\n",
    "\n",
    "r = session.get(\"http://httpbin.org/ip\")\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turned out that fake useragent is enough, and tor with changing IPs is not necessary\n",
    "# !service tor start\n",
    "\n",
    "# session = requests.session()\n",
    "# session.proxies = {}\n",
    "\n",
    "# session.proxies['http'] = 'socks4://localhost:9051'\n",
    "# session.proxies['https'] = 'socks4://localhost:9051'\n",
    "\n",
    "# r = session.get(\"http://httpbin.org/ip\")\n",
    "# print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13502\n"
     ]
    }
   ],
   "source": [
    "ticker_df = pd.read_csv(\"tickers.csv\", names=['ticker'])\n",
    "tickers = ticker_df['ticker'].tolist()\n",
    "print(len(tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13502 tickers is a lot. Executing all this in a row takes a couple of hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits_data(t: str) -> pd.DataFrame:\n",
    "    \"\"\"Get data on single ticker\"\"\"\n",
    "    \n",
    "    ticker = t.lower()\n",
    "    regex_split_info = re.compile(r\"(\\d{2}/\\d{2}/\\d{4})\\s*([\\d.]+?)(\\s*for\\s*)(\\s*[\\d.]+)\")  # x for x part - split ratio\n",
    "    \n",
    "\n",
    "    r = session.get(\"https://www.stocksplithistory.com/{}/\".format(ticker), timeout = 10,\n",
    "                    headers={'User-Agent': UserAgent().chrome})\n",
    "\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "    all_text = ' '.join(soup.findAll(text=True)).replace('\\n\\n', '')\n",
    "    \n",
    "    try:\n",
    "        tab = re.findall(r\"{}\\s*split\\s*history\\s*.*?stock\\s*splits\".format(ticker), all_text.lower(), flags=re.DOTALL)[0]\n",
    "    except IndexError:\n",
    "        return  # no info on this ticker at all\n",
    "    if 'for' in tab:\n",
    "        splits = regex_split_info.findall(tab)\n",
    "        if splits:\n",
    "            return pd.DataFrame([(ticker.upper(), x[0], float(x[1]), float(x[3])) for x in splits], columns=['ticker', 'date', 'now', 'was'])\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>now</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>06/16/1987</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>06/21/2000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>02/28/2005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>06/09/2014</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        date  now  was\n",
       "0   AAPL  06/16/1987  2.0  1.0\n",
       "1   AAPL  06/21/2000  2.0  1.0\n",
       "2   AAPL  02/28/2005  2.0  1.0\n",
       "3   AAPL  06/09/2014  7.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_splits_data(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "CPU times: user 15min 24s, sys: 2min 42s, total: 18min 7s\n",
      "Wall time: 17min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = None\n",
    "while 1:\n",
    "    with ThreadPoolExecutor(max_workers=70) as pool:  # arbitrary value - too much causes problems as well\n",
    "        future = [pool.submit(get_splits_data, ticker) for ticker in tickers]\n",
    "    \n",
    "    try:\n",
    "        data_temp = pd.concat([x.result() for x in future if x.done()\n",
    "                        and not x.exception()\n",
    "                        and x.result() is not None], ignore_index=True)  # concatenation of data for tickers\n",
    "    except ValueError:\n",
    "        data_temp = None\n",
    "    \n",
    "    if data_temp is not None:\n",
    "        if data is None:\n",
    "            data = data_temp\n",
    "        else:\n",
    "            data = pd.concat([data, data_temp], ignore_index=True)\n",
    "        \n",
    "    number_of_runs_with_errors = len([x.exception() for x in future if x.exception()])  # timeout errors, connection refuses\n",
    "    print(number_of_runs_with_errors)\n",
    "    if number_of_runs_with_errors == 0:\n",
    "        break\n",
    "        \n",
    "    errored = list(filter(lambda x: x[0] is not None, zip([x.exception() for x in future], tickers)))\n",
    "    tickers = [x[1] for x in errored]  # new tickers list - those that with errors. Scraping them once again\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8246, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3446,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ticker'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this result is actually pretty nice - less than 20 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
